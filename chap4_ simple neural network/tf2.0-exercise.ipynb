{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTSJSP2iytw-"
      },
      "source": [
        "# Tensorflow2.0 小练习"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8odYglmpytxB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRZz2nsQytxC"
      },
      "source": [
        "## 实现softmax函数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouL49-BUytxD",
        "outputId": "f74f2898-0573-4fb1-e233-41fc2d17d5f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def softmax(x):\n",
        "    # 计算指数\n",
        "    exp_x = tf.exp(x)\n",
        "    # 对最后一维求和\n",
        "    sum_exp_x = tf.reduce_sum(exp_x, axis=-1, keepdims=True)\n",
        "    # 计算概率\n",
        "    prob_x = exp_x / sum_exp_x\n",
        "    return prob_x\n",
        "\n",
        "test_data = np.random.normal(size=[10, 5])\n",
        "(softmax(test_data).numpy() - tf.nn.softmax(test_data, axis=-1).numpy())**2 <0.0001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk7CjbSbytxE"
      },
      "source": [
        "## 实现sigmoid函数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLhM5d-LytxE",
        "outputId": "a652ad78-71c7-45a2-a67d-72b5fd1edc1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def sigmoid(x):\n",
        "    # 实现 sigmoid 公式：1/(1+e^(-x))\n",
        "    prob_x = 1 / (1 + tf.exp(-x))\n",
        "    return prob_x\n",
        "\n",
        "test_data = np.random.normal(size=[10, 5])\n",
        "(sigmoid(test_data).numpy() - tf.nn.sigmoid(test_data).numpy())**2 < 0.0001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEzdVApJytxE"
      },
      "source": [
        "## 实现 softmax 交叉熵loss函数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpjLujugytxF",
        "outputId": "796c4462-5334-4933-d96b-da5ebd6bf3ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.True_"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def softmax_ce(x, label):\n",
        "    eps = 1e-12\n",
        "    x = np.clip(x, eps, 1 - eps)  # 限制 x 在 [eps, 1-eps] 避免数值问题\n",
        "    loss = -np.sum(label * np.log(x), axis=-1)  # 对类别维度求和\n",
        "    return np.mean(loss)  # 对样本维度求平均\n",
        "\n",
        "test_data = np.random.normal(size=[10, 5])\n",
        "prob = tf.nn.softmax(test_data)\n",
        "label = np.zeros_like(test_data)\n",
        "label[np.arange(10), np.random.randint(0, 5, size=10)]=1.\n",
        "\n",
        "((tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(label, test_data))\n",
        "  - softmax_ce(prob, label))**2 < 0.0001).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXd9qdE7ytxF"
      },
      "source": [
        "## 实现 sigmoid 交叉熵loss函数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2fd6JDEytxF",
        "outputId": "1a483d91-0d37-4a7f-9c60-8ae51bc7dcc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1. 0. 0. 1. 0. 0. 1. 0. 0. 1.]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "np.True_"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def sigmoid_ce(x, label):\n",
        "    eps = 1e-12  # 添加小值避免 log(0)\n",
        "    x = np.clip(x, eps, 1 - eps)  # 限制 x 在 [eps, 1-eps] 避免数值问题\n",
        "    loss = -(label * np.log(x) + (1 - label) * np.log(1 - x))\n",
        "    return np.mean(loss)  # 对样本取平均\n",
        "\n",
        "test_data = np.random.normal(size=[10])\n",
        "prob = tf.nn.sigmoid(test_data)\n",
        "label = np.random.randint(0, 2, 10).astype(test_data.dtype)\n",
        "print (label)\n",
        "\n",
        "((tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(label, test_data))- sigmoid_ce(prob, label))**2 < 0.0001).numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WNmjLwxytxF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Next_Token_Prediction",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
